# -*- coding: utf-8 -*-
"""CODSOFT - 5 ( Credit Card Fraud )

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1panqhwAoMHeusxIat5vaigKuyjgvxKNF

# **Credit Card Fraud**

This project aims to build a machine learning model to accurately identify fraudulent credit card transactions. The dataset is highly imbalanced, meaning that genuine transactions far outnumber fraudulent ones. The workflow includes robust data preprocessing, a technique to handle the class imbalance, model training, and a comprehensive evaluation of the model's performance.

## **Importing Libraries**
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

"""## **Data Preprocessing and Exploratory Data Analysis (EDA)**"""

# Load the dataset (assuming 'creditcard.csv' is available)
df = pd.read_csv('creditcard.csv')

# Preprocessing
scaler = StandardScaler()
df['Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))
df.drop(['Time'], axis=1, inplace=True)

# Define features and target
X = df.drop('Class', axis=1)
y = df['Class']

print("Initial class distribution:")
print(y.value_counts())

"""The first step is to load and prepare the dataset. The dataset contains a mix of numerical and anonymized features (V1 to V28), Time, Amount, and the target variable Class (0 for genuine, 1 for fraud).

* **Normalization:** The Amount and Time columns, which are not anonymized, are standardized to have a mean of 0 and a standard deviation of 1. This ensures that their scales do not unfairly influence the model.

* **Feature and Target Definition:** The dataset is split into features (X) and the target variable (y).

## **Handling Class Imbalance (Advanced Feature)**
"""

# Handle missing values in y by dropping corresponding rows in X and y
nan_mask = y.isna()
X = X[~nan_mask]
y = y[~nan_mask]

# Apply SMOTE to handle imbalanced data
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

print("\nClass distribution after SMOTE:")
print(y_res.value_counts())

"""The dataset is severely imbalanced, with fraudulent transactions making up less than 0.2% of the data. Training a model on this data would likely result in it being highly biased towards the majority class (genuine transactions).

To address this, the **Synthetic Minority Over-sampling Technique (SMOTE)** is used. SMOTE creates new, synthetic samples of the minority class (fraudulent transactions) by interpolating between existing minority samples. This balances the dataset, allowing the model to learn the patterns of fraudulent behavior more effectively.

## **Model Building and Evaluation**
"""

# Split the resampled data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)

# Initialize and train the RandomForestClassifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

"""* **Data Splitting:** The balanced dataset is split into a training set and a testing set.

* **Model Selection:** A RandomForestClassifier is chosen for its robustness and ability to handle complex non-linear relationships.

* **Training:** The model is trained on the resampled training data.

* **Prediction:** The trained model makes predictions on the unseen test set.

## **Results and Analysis**
"""

# Evaluate the model
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

# Plot the confusion matrix for better visualization
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Genuine', 'Fraud'], yticklabels=['Genuine', 'Fraud'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for Fraud Detection')
plt.show()

"""The model's performance is evaluated using metrics that are crucial for imbalanced classification problems: precision, recall, and f1-score.

* **Precision:** Of all the transactions the model predicted as fraudulent, this metric tells us how many were actually fraudulent.

* **Recall:** Of all the actual fraudulent transactions, this metric tells us how many the model successfully identified.

* **F1-score:** This is the harmonic mean of precision and recall, providing a balanced measure of the model's accuracy.

The results show that the model performs exceptionally well at detecting fraudulent transactions. The confusion matrix visually represents the correct and incorrect predictions, with high true positive and true negative rates.
"""